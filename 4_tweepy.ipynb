{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_tweepy.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-Mundra/Mccombs_course/blob/master/4_tweepy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy0IHWws4DLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a file from Google Drive using FILE_ID\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive tweepy\n",
        "import os \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBomhsgk4FJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: 1rhnzJ8CD9Amdz5OMi8s4kqT5b00jY5k4\n",
        "# Visit https://help.meiro.io/en/articles/2245027-where-can-i-find-the-file-id-on-google-drive\n",
        "# for more details on getting the FILE ID.\n",
        "\n",
        "def download_file(file_id, file_name):\n",
        "    '''\n",
        "    file_id: Make sure that you can access this file from your account or else, this will not run\n",
        "    file_name: Name of the file by which you want to save\n",
        "    '''\n",
        "    downloaded = drive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(file_name)\n",
        "    print('Downloaded file with ID {} and name {}'.format(file_id, file_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfvWW2N74HNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34f0fe75-3278-4b01-c680-623f7fd2a6bb"
      },
      "source": [
        "if not os.path.isfile('secrets.txt'):\n",
        "    download_file('1zf_8E7G1-o4ywB4cnjUa-aVl_mMSxlyH', 'secrets.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded file with ID 1zf_8E7G1-o4ywB4cnjUa-aVl_mMSxlyH and name secrets.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrznqrzpIJVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can store secrets in a file or in the form of environment variables during production.\n",
        "# NEVER store keys directly on notebook.\n",
        "\n",
        "with open('secrets.txt', 'r') as file:\n",
        "    data = file.read().split('\\n')\n",
        "\n",
        "import tweepy \n",
        "import pandas as pd\n",
        "\n",
        "consumer_key = data[0]\n",
        "consumer_secret = data[1]\n",
        "access_key = data[2]\n",
        "access_secret = data[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21bRvTQ-30SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_user_tweets(screen_name, num=0):\n",
        "    #Twitter only allows access to a users most recent 3000 tweets with this method\n",
        "    num = 3000 if num > 3000 else num\n",
        "    max_num_per_call = 200\n",
        "\n",
        "    #authorize twitter, initialize tweepy\n",
        "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "    auth.set_access_token(access_key, access_secret)\n",
        "    api = tweepy.API(auth)\n",
        "    \n",
        "    #initialize a list to hold all the tweepy Tweets\n",
        "    alltweets = []    \n",
        "    \n",
        "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
        "    curr_count = max_num_per_call if num > max_num_per_call else num\n",
        "    num -= curr_count\n",
        "\n",
        "    new_tweets = api.user_timeline(screen_name=screen_name, count=curr_count)\n",
        "    \n",
        "    tweet = new_tweets[0]\n",
        "    print(f\"Location of username {screen_name} is: {tweet.user.location}\\n\")\n",
        "    \n",
        "    #save most recent tweets\n",
        "    alltweets.extend(new_tweets)\n",
        "    \n",
        "    #save the id of the oldest tweet less one\n",
        "    oldest = alltweets[-1].id - 1\n",
        "\n",
        "    print(f\"{len(alltweets)} tweets downloaded so far\")\n",
        "    \n",
        "    #keep grabbing tweets until there are no tweets left to grab\n",
        "    while num > 0:\n",
        "        print(f\"Getting tweets before {oldest}\")\n",
        "        \n",
        "        curr_count = max_num_per_call if num > max_num_per_call else num\n",
        "\n",
        "        #all subsiquent requests use the max_id param to prevent duplicates\n",
        "        new_tweets = api.user_timeline(screen_name = screen_name, count=curr_count, max_id=oldest)\n",
        "        num -= curr_count\n",
        "        \n",
        "        #save most recent tweets\n",
        "        alltweets.extend(new_tweets)\n",
        "        \n",
        "        #update the id of the oldest tweet less one\n",
        "        oldest = alltweets[-1].id - 1\n",
        "        \n",
        "        print(f\"{len(alltweets)} tweets downloaded so far\")\n",
        "    \n",
        "    #transform the tweepy tweets into a 2D array that will populate the csv    \n",
        "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
        "    df = pd.DataFrame(outtweets, columns=[\"id\",\"created_at\",\"text\"])\n",
        "    df.to_csv(f\"user_{screen_name}.csv\", index=False)\n",
        "    print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4nuDmeIGWsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = {\n",
        "    'AL': 'Alabama',\n",
        "    'AK': 'Alaska',\n",
        "    'AZ': 'Arizona',\n",
        "    'AR': 'Arkansas',\n",
        "    'CA': 'California',\n",
        "    'CO': 'Colorado',\n",
        "    'CT': 'Connecticut',\n",
        "    'DE': 'Delaware',\n",
        "    'DC': 'District of Columbia',\n",
        "    'FL': 'Florida',\n",
        "    'GA': 'Georgia',\n",
        "    'HI': 'Hawaii',\n",
        "    'ID': 'Idaho',\n",
        "    'IL': 'Illinois',\n",
        "    'IN': 'Indiana',\n",
        "    'IA': 'Iowa',\n",
        "    'KS': 'Kansas',\n",
        "    'KY': 'Kentucky',\n",
        "    'LA': 'Louisiana',\n",
        "    'ME': 'Maine',\n",
        "    'MD': 'Maryland',\n",
        "    'MA': 'Massachusetts',\n",
        "    'MI': 'Michigan',\n",
        "    'MN': 'Minnesota',\n",
        "    'MS': 'Mississippi',\n",
        "    'MO': 'Missouri',\n",
        "    'MT': 'Montana',\n",
        "    'NE': 'Nebraska',\n",
        "    'NV': 'Nevada',\n",
        "    'NH': 'New Hampshire',\n",
        "    'NJ': 'New Jersey',\n",
        "    'NM': 'New Mexico',\n",
        "    'NY': 'New York',\n",
        "    'NC': 'North Carolina',\n",
        "    'ND': 'North Dakota',\n",
        "    'OH': 'Ohio',\n",
        "    'OK': 'Oklahoma',\n",
        "    'OR': 'Oregon',\n",
        "    'PA': 'Pennsylvania',\n",
        "    'RI': 'Rhode Island',\n",
        "    'SC': 'South Carolina',\n",
        "    'SD': 'South Dakota',\n",
        "    'TN': 'Tennessee',\n",
        "    'TX': 'Texas',\n",
        "    'UT': 'Utah',\n",
        "    'VT': 'Vermont',\n",
        "    'VA': 'Virginia',\n",
        "    'WA': 'Washington',\n",
        "    'WV': 'West Virginia',\n",
        "    'WI': 'Wisconsin',\n",
        "    'WY': 'Wyoming'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt_thZXW-7It",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_query_tweets(query, num=0):\n",
        "    num = 3000 if num > 3000 else num\n",
        "    max_num_per_call = 100\n",
        "\n",
        "    #authorize twitter, initialize tweepy\n",
        "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "    auth.set_access_token(access_key, access_secret)\n",
        "    api = tweepy.API(auth)\n",
        "    \n",
        "    #initialize a list to hold all the tweepy Tweets\n",
        "    alltweets = []    \n",
        "    \n",
        "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
        "    curr_count = max_num_per_call if num > max_num_per_call else num\n",
        "    num -= curr_count\n",
        "\n",
        "    new_tweets = api.search(q=query, count=curr_count)\n",
        "    \n",
        "    #save most recent tweets\n",
        "    alltweets.extend(new_tweets)\n",
        "    \n",
        "    #save the id of the oldest tweet less one\n",
        "    oldest = alltweets[-1].id - 1\n",
        "    \n",
        "    print(f\"{len(alltweets)} tweets downloaded so far\")\n",
        "\n",
        "    #keep grabbing tweets until there are no tweets left to grab\n",
        "    while num > 0:\n",
        "        print(f\"Getting tweets before {oldest}\")\n",
        "        \n",
        "        curr_count = max_num_per_call if num > max_num_per_call else num\n",
        "\n",
        "        #all subsiquent requests use the max_id param to prevent duplicates\n",
        "        new_tweets = api.search(q=query, count=curr_count, max_id=oldest)\n",
        "        num -= curr_count\n",
        "        \n",
        "        #save most recent tweets\n",
        "        alltweets.extend(new_tweets)\n",
        "        \n",
        "        #update the id of the oldest tweet less one\n",
        "        oldest = alltweets[-1].id - 1\n",
        "        \n",
        "        print(f\"{len(alltweets)} tweets downloaded so far\")\n",
        "    \n",
        "    #transform the tweepy tweets into a 2D array that will populate the csv    \n",
        "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\"), tweet.user.location] for tweet in alltweets]\n",
        "    df = pd.DataFrame(outtweets, columns=[\"id\", \"created_at\", \"text\", \"location\"])\n",
        "    df.to_csv(f\"query_{query}.csv\", index=False)\n",
        "    print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQHCjwNk75i1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "3c13c69a-00bb-4926-a946-df3e30b67bd5"
      },
      "source": [
        "# pass in the username of the account you want to download\n",
        "get_user_tweets(\"TwitterMusic\", 390)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Location of username TwitterMusic is: Twitter HQ\n",
            "\n",
            "200 tweets downloaded so far\n",
            "Getting tweets before 1172258530344210441\n",
            "390 tweets downloaded so far\n",
            "                    id  ...                                               text\n",
            "0  1183423921284157441  ...  b'RT @halsey: stan twitter is crazy cause i me...\n",
            "1  1183120180446142466  ...                 b'@psih_polunoch \\xf0\\x9f\\x92\\x9c'\n",
            "2  1183118670140182529  ...                          b'@umidiotaamenos agreed'\n",
            "3  1183118331777343489  ...  b'@owengdriscoll *nods head in approval* this ...\n",
            "4  1183111570265640961  ...     b\"What's your holy trinity? #NationalAlbumDay\"\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykzq6zblCILU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "0edd0801-98e9-4126-a7f3-a25683407eb0"
      },
      "source": [
        "# pass in the search query\n",
        "get_query_tweets(\"Management\", 290)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 tweets downloaded so far\n",
            "Getting tweets before 1183570976572891136\n",
            "190 tweets downloaded so far\n",
            "                    id  ...               location\n",
            "0  1183571861210316801  ...                       \n",
            "1  1183571844588175360  ...              Australia\n",
            "2  1183571839164936193  ...       Calgary, Alberta\n",
            "3  1183571818671726592  ...                  India\n",
            "4  1183571816255647744  ...  All Around The World \n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNdaKIpUHb53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}